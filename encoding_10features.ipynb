{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ed3a4-c790-4229-8f15-33ec4fd38788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "global nop, non\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "# from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def readPeptide(pepfile, lr):\n",
    "    data = []\n",
    "    lr = 30 - lr\n",
    "    with open(pepfile, 'r') as f:\n",
    "        for line in f:\n",
    "            # print(line.rstrip().split('\\t')[0])\n",
    "            if lr == 0:\n",
    "                data.append(line.rstrip().split('\\t')[0])\n",
    "            else:\n",
    "                data.append(line.rstrip().split('\\t')[0][lr:-lr])\n",
    "    return data\n",
    "\n",
    "\n",
    "def find_all_index(arr, item):\n",
    "    return [i for i, a in enumerate(arr) if a == item]\n",
    "\n",
    "\n",
    "def command_pssm(input_file, output_file, pssm_file, DBname):\n",
    "    import subprocess\n",
    "    cmd1 = r'/home/data/t080305/Xiamen/KCR_new/ncbi-blast-2.16.0+/bin/psiblast -query ' + input_file + ' -db ' + DBname + ' -num_iterations 3 -num_threads 12 -out ' + output_file + ' -out_ascii_pssm ' + pssm_file #path of psiblast\n",
    "    # wt.write(time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':pssm11'+input_file+'\\n')\n",
    "    subprocess.check_call(cmd1, shell=True)\n",
    "    # print(cmd1)\n",
    "\n",
    "\n",
    "def GetPSSM(ProSeq, OutDir, PSSMDir, DBname):\n",
    "    from Bio import SeqIO\n",
    "    records = list(SeqIO.parse(ProSeq, \"fasta\"))\n",
    "\n",
    "    global aa1\n",
    "    aa1 = {}\n",
    "    # aa=open('../../pssm/aa.txt','a')\n",
    "    for i, item in enumerate(records):\n",
    "        if not os.path.exists(r'ZID/'):\n",
    "            os.makedirs(r'ZID/')\n",
    "        # print(records[i].seq,records[i].seq in ppf,ppf.__len__())\n",
    "        if records[i].seq in ppf:\n",
    "            seq1 = records[i].seq\n",
    "            # print(seq1)\n",
    "            if ppf[seq1].split('\\t')[1] == 'nan': continue\n",
    "            input1 = ppf[seq1].split('\\t')[1]\n",
    "            input2 = ppf[seq1].split('\\t')[2]\n",
    "            if (not os.path.exists(input1)) or (not os.path.exists(input2)): continue\n",
    "            out1 = PSSMDir + r'/' + records[i].id.split('|')[1] + '.pssm'\n",
    "            out2 = PSSMDir[:-14] + r'/asa_result2/' + records[i].id.split('|')[1] + '.txt'\n",
    "            import shutil\n",
    "            shutil.copy(input1, out1)\n",
    "            shutil.copy(input2, out2)\n",
    "            # print(seq1,records[i].seq)\n",
    "            aa1[str(seq1)] = input1\n",
    "        else:\n",
    "            input_file = r'ZID/' + records[i].id.split('|')[1] + '.fa'\n",
    "            SeqIO.write(records[i], input_file, 'fasta')\n",
    "\n",
    "            output_file = OutDir + r'/' + records[i].id.split('|')[1] + '.out'\n",
    "            pssm_file = PSSMDir + r'/' + records[i].id.split('|')[1] + '.pssm'\n",
    "\n",
    "            if not os.path.exists(pssm_file):\n",
    "                command_pssm(input_file, output_file, pssm_file, DBname)\n",
    "            aa1[str(records[i].seq)] = pssm_file\n",
    "\n",
    "\n",
    "def StandardpPSSM(OldPSMMdir):\n",
    "    listfile = os.listdir(OldPSMMdir)\n",
    "    if listfile.__len__() == 0:\n",
    "        import shutil\n",
    "        shutil.copy('../1.pssm', OldPSMMdir)\n",
    "    listfile = os.listdir(OldPSMMdir)\n",
    "    FinPSSM, num1 = [], []\n",
    "    for i, eachfile in enumerate(listfile):\n",
    "        num1.append(int(eachfile.split('.')[0]))\n",
    "    num = sorted(num1)\n",
    "    for i, nn in enumerate(num):\n",
    "        eachfile = str(nn) + '.pssm'\n",
    "        with open(OldPSMMdir + '/' + eachfile, 'r') as inputpssm:\n",
    "            count = 0\n",
    "            Dirdata = []\n",
    "            for line in inputpssm:\n",
    "                count += 1\n",
    "                if count <= 3:\n",
    "                    continue\n",
    "                if line.count('\\n') == len(line):\n",
    "                    break\n",
    "                temp = line.strip().split()[2:22]\n",
    "                Dirdata.append(temp)\n",
    "            DirdataR = np.array(Dirdata)\n",
    "            DirPSSM = np.reshape(DirdataR, (1, DirdataR.shape[0] * DirdataR.shape[1])).tolist()\n",
    "            FinPSSM.append(DirPSSM[0])\n",
    "\n",
    "    return FinPSSM, num\n",
    "\n",
    "\n",
    "def psStandardpPSSM(OldPSMMdir):\n",
    "    listfile = os.listdir(OldPSMMdir)\n",
    "    if listfile.__len__() == 0:\n",
    "        import shutil\n",
    "        shutil.copy('../1.txt', OldPSMMdir)\n",
    "    listfile = os.listdir(OldPSMMdir)\n",
    "    FinPSSM, FinPSSM0, FinPSSM1, num1 = [], [], [], []\n",
    "    for i, eachfile in enumerate(listfile):\n",
    "        # print(eachfile)\n",
    "        # num1.append(int(eachfile.split('.')[0]))\n",
    "        num1.append(eachfile.split('.')[0])\n",
    "    num = sorted(num1)\n",
    "    namesout = []\n",
    "    # global namesout\n",
    "    for i, nn in enumerate(num):\n",
    "        eachfile = str(nn) + '.txt'\n",
    "        # print(eachfile)\n",
    "        with open(OldPSMMdir + '/' + eachfile, 'r') as inputpssm:\n",
    "            count = 0\n",
    "            Dirdata, Dirdata0, Dirdata1, Dirdata2, Dirdata3 = [], [], [], [], []\n",
    "            Dirdata4, Dirdata5, Dirdata6, Dirdata7, Dirdata8 = [], [], [], [], []\n",
    "            for line in inputpssm:\n",
    "                count += 1\n",
    "                if count <= 1:\n",
    "                    continue\n",
    "                if len(line) < 2:\n",
    "                    break\n",
    "                # print(line)\n",
    "                temp = float(line.strip().split('\\t')[3])\n",
    "                Dirdata.append(temp)\n",
    "                temp0 = float(line.strip().split('\\t')[8])\n",
    "                Dirdata0.append(temp0)\n",
    "                temp1 = float(line.strip().split('\\t')[9])\n",
    "                Dirdata1.append(temp1)\n",
    "                temp2 = float(line.strip().split('\\t')[10])\n",
    "                Dirdata2.append(temp2)\n",
    "                temp3 = float(line.strip().split('\\t')[4])\n",
    "                Dirdata4.append(temp3)\n",
    "                temp4 = float(line.strip().split('\\t')[5])\n",
    "                Dirdata5.append(temp4)\n",
    "                temp5 = float(line.strip().split('\\t')[6])\n",
    "                Dirdata6.append(temp5)\n",
    "                temp6 = float(line.strip().split('\\t')[7])\n",
    "                Dirdata7.append(temp6)\n",
    "\n",
    "            Dirdata3 = Dirdata0 + Dirdata1 + Dirdata2\n",
    "            Dirdata8 = Dirdata4 + Dirdata5 + Dirdata6 + Dirdata7\n",
    "            # if Dirdata == [] or len(Dirdata) != 61:\n",
    "            # print(len(Dirdata))\n",
    "            # continue\n",
    "            FinPSSM.append(Dirdata)\n",
    "            FinPSSM0.append(Dirdata3)\n",
    "            FinPSSM1.append(Dirdata8)\n",
    "            namesout.append(nn)\n",
    "            # print(len(Dirdata),len(Dirdata3),len(Dirdata8))#61 183 244\n",
    "    # print(FinPSSM[0],FinPSSM[1],FinPSSM[2],FinPSSM[3])\n",
    "    # print(FinPSSM0[0], FinPSSM0[1], FinPSSM0[2], FinPSSM0[3])\n",
    "    # print(FinPSSM1[0], FinPSSM1[1], FinPSSM1[2], FinPSSM1[3])\n",
    "    # FinPSSM=np.array(FinPSSM).reshape(len(num),len(Dirdata))\n",
    "    # FinPSSM0 = np.array(FinPSSM0).reshape(len(num), len(Dirdata3))\n",
    "    # FinPSSM1 = np.array(FinPSSM1).reshape(len(num), len(Dirdata8))\n",
    "    # print(np.array(FinPSSM).shape,np.array(FinPSSM0).shape,np.array(FinPSSM1).shape)\n",
    "\n",
    "    return FinPSSM, FinPSSM0, FinPSSM1, num, namesout\n",
    "    # FinPSSM:asa FinPSSM0:二级结构 FinPSSM1：四个角度\n",
    "    # secondary structure type, ASA, φ, ψ, θ, τ, and probabilities as coil (C), sheet (E), and helix (H)\n",
    "\n",
    "\n",
    "def readweight(weight_file):\n",
    "    weight = None\n",
    "    with open(weight_file, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 2 - 1:\n",
    "                weight = np.array([float(x) for x in line.rstrip().split('\\t')])\n",
    "    return weight\n",
    "\n",
    "\n",
    "def read_pssm(pssm_file):\n",
    "    # this function reads the pssm file given as input, and returns a LEN x 20 matrix of pssm values.\n",
    "    # index of 'ACDE..' in 'ARNDCQEGHILKMFPSTWYV'(blast order)\n",
    "    idx_res = (0, 4, 3, 6, 13, 7, 8, 9, 11, 10, 12, 2, 14, 5, 1, 15, 16, 19, 17, 18)\n",
    "    # open the two files, read in their data and then close them\n",
    "    # declare the empty dictionary with each of the entries\n",
    "    aa = []\n",
    "    pssm = []\n",
    "    # iterate over the pssm file and get the needed information out\n",
    "    with open(pssm_file) as inputpssm:\n",
    "        count = 0\n",
    "        for line in inputpssm:\n",
    "\n",
    "            count += 1\n",
    "            if count <= 3:\n",
    "                continue\n",
    "            if line.count('\\n') == len(line):\n",
    "                break\n",
    "            temp = line.strip().split()[2:22]\n",
    "            aa_temp = line.strip().split()[1]\n",
    "            aa.append(aa_temp)\n",
    "            pssm_temp = [-float(i) for i in temp]\n",
    "            pssm.append([pssm_temp[k] for k in idx_res])\n",
    "    return aa, pssm\n",
    "\n",
    "\n",
    "def get_phys7(aa):\n",
    "    # this function takes a path to a pssm file and finds the pssm + phys 7 input\n",
    "    # to the NN in the required order - with the required window size (8).\n",
    "    # define the dictionary with the phys properties for each AA\n",
    "    phys_dic = {'A': [-0.350, -0.680, -0.677, -0.171, -0.170, 0.900, -0.476],\n",
    "                'C': [-0.140, -0.329, -0.359, 0.508, -0.114, -0.652, 0.476],\n",
    "                'D': [-0.213, -0.417, -0.281, -0.767, -0.900, -0.155, -0.635],\n",
    "                'E': [-0.230, -0.241, -0.058, -0.696, -0.868, 0.900, -0.582],\n",
    "                'F': [0.363, 0.373, 0.412, 0.646, -0.272, 0.155, 0.318],\n",
    "                'G': [-0.900, -0.900, -0.900, -0.342, -0.179, -0.900, -0.900],\n",
    "                'H': [0.384, 0.110, 0.138, -0.271, 0.195, -0.031, -0.106],\n",
    "                'I': [0.900, -0.066, -0.009, 0.652, -0.186, 0.155, 0.688],\n",
    "                'K': [-0.088, 0.066, 0.163, -0.889, 0.727, 0.279, -0.265],\n",
    "                'L': [0.213, -0.066, -0.009, 0.596, -0.186, 0.714, -0.053],\n",
    "                'M': [0.110, 0.066, 0.087, 0.337, -0.262, 0.652, -0.001],\n",
    "                'N': [-0.213, -0.329, -0.243, -0.674, -0.075, -0.403, -0.529],\n",
    "                'P': [0.247, -0.900, -0.294, 0.055, -0.010, -0.900, 0.106],\n",
    "                'Q': [-0.230, -0.110, -0.020, -0.464, -0.276, 0.528, -0.371],\n",
    "                'R': [0.105, 0.373, 0.466, -0.900, 0.900, 0.528, -0.371],\n",
    "                'S': [-0.337, -0.637, -0.544, -0.364, -0.265, -0.466, -0.212],\n",
    "                'T': [0.402, -0.417, -0.321, -0.199, -0.288, -0.403, 0.212],\n",
    "                'V': [0.677, -0.285, -0.232, 0.331, -0.191, -0.031, 0.900],\n",
    "                'W': [0.479, 0.900, 0.900, 0.900, -0.209, 0.279, 0.529],\n",
    "                'Y': [0.363, 0.417, 0.541, 0.188, -0.274, -0.155, 0.476]}\n",
    "    # set the phys7 data.\n",
    "    phys = [phys_dic.get(i, phys_dic['A']) for i in aa]\n",
    "    return phys\n",
    "\n",
    "\n",
    "def window(feat, winsize=8):\n",
    "    # apply the windowing to the input feature\n",
    "    feat = np.array(feat)\n",
    "    output = np.concatenate([np.vstack([feat[0]] * winsize), feat])\n",
    "    output = np.concatenate([output, np.vstack([feat[-1]] * winsize)])\n",
    "    output = [np.ndarray.flatten(output[i:i + 2 * winsize + 1]).T for i in range(0, feat.shape[0])]\n",
    "    return output\n",
    "\n",
    "\n",
    "def window_data(*feature_types):\n",
    "    n = len(feature_types[0])\n",
    "    features = np.empty([n, 0])\n",
    "    for feature_type in feature_types:\n",
    "        test = np.array(window(feature_type))\n",
    "        features = np.concatenate((features, test), axis=1)\n",
    "    return features\n",
    "\n",
    "\n",
    "def sigmoid(input):\n",
    "    # apply the sigmoid function\n",
    "    output = 1 / (1 + np.exp(-input))\n",
    "    return (output)\n",
    "\n",
    "\n",
    "def nn_feedforward(nn, input):\n",
    "    input = np.matrix(input)\n",
    "    # find the number of layers in the NN so that we know how much to iterate over\n",
    "    num_layers = nn['n'][0][0][0][0]\n",
    "    # num_input is the number of input AAs, not the dimentionality of the features\n",
    "    num_input = input.shape[0]\n",
    "    x = input\n",
    "    # for each layer up to the final\n",
    "    for i in range(1, num_layers - 1):\n",
    "        # get the bais and weights out of the nn\n",
    "        W = nn['W'][0][0][0][i - 1].T\n",
    "        temp_size = x.shape[0]\n",
    "        b = np.ones((temp_size, 1))\n",
    "        x = np.concatenate((b, x), axis=1)\n",
    "        # find the output of this layer (the input to the next)\n",
    "        xw = np.dot(x, W)\n",
    "        x = sigmoid(xw)\n",
    "    # for the final layer.\n",
    "    # note that this layer is done serpately, this is so that if the output nonlinearity\n",
    "    # is not sigmoid, it can be calculated seperately.\n",
    "    W = nn['W'][0][0][0][-1].T\n",
    "    b = np.ones((x.shape[0], 1))\n",
    "    x = np.concatenate((b, x), axis=1)\n",
    "    output = np.dot(x, W)  # x*W\n",
    "    pred = sigmoid(output)\n",
    "    return pred\n",
    "\n",
    "\n",
    "dict_ASA0 = dict(zip(\"ACDEFGHIKLMNPQRSTVWY\",\n",
    "                     (115, 135, 150, 190, 210, 75, 195, 175, 200, 170,\n",
    "                      185, 160, 145, 180, 225, 115, 140, 155, 255, 230)))\n",
    "\n",
    "\n",
    "def run_iter(dict_nn, input_feature0, aa, ofile):\n",
    "    SS_order = ('C' 'E' 'H')\n",
    "    list1 = ('SS', 'ASA', 'TTPP')\n",
    "    list_res1 = []\n",
    "    for x in list1:\n",
    "        nn = dict_nn[x]\n",
    "        norm_max = nn['high'][0][0][0]\n",
    "        norm_min = nn['low'][0][0][0]\n",
    "        input_feature1 = (input_feature0 - np.tile(norm_min, (input_feature0.shape[0], 1))) / np.tile(\n",
    "            (norm_max - norm_min), (input_feature0.shape[0], 1))\n",
    "        r1 = nn_feedforward(nn, input_feature1)\n",
    "        list_res1.append(r1)\n",
    "    pred_ss_1, pred_asa_1, pred_ttpp_1 = list_res1\n",
    "    SS_1 = [SS_order[i.tolist()[0][0]] for i in np.argmax(pred_ss_1, 1)]\n",
    "    pred_ttpp_1_denorm = (pred_ttpp_1 - 0.5) * 2\n",
    "    theta = np.degrees(np.arctan2(pred_ttpp_1_denorm[:, 0], pred_ttpp_1_denorm[:, 2]))\n",
    "    tau = np.degrees(np.arctan2(pred_ttpp_1_denorm[:, 1], pred_ttpp_1_denorm[:, 3]))\n",
    "    phi = np.degrees(np.arctan2(pred_ttpp_1_denorm[:, 4], pred_ttpp_1_denorm[:, 6]))\n",
    "    psi = np.degrees(np.arctan2(pred_ttpp_1_denorm[:, 5], pred_ttpp_1_denorm[:, 7]))\n",
    "    if ofile == 'NULL':\n",
    "        return SS_1, pred_ss_1, pred_asa_1, theta, tau, phi, psi\n",
    "    fp = open(ofile, 'w')\n",
    "    fp.write('#\\tAA\\tSS\\tASA\\tPhi\\tPsi\\tTheta(i-1=>i+1)\\tTau(i-2=>i+1)\\tP(C)\\tP(E)\\tP(H)')\n",
    "    fp.write('\\n')\n",
    "    for ind, x in enumerate(aa):\n",
    "        asa = pred_asa_1[ind] * dict_ASA0.get(x, dict_ASA0['A'])\n",
    "\n",
    "        fp.write(('%i\\t%c\\t%c\\t%5.1f' + '\\t%6.1f' * 4 + '\\t%.3f' * 3) % (\n",
    "            ind + 1, x, SS_1[ind], asa, phi[ind], psi[ind], theta[ind], tau[ind], pred_ss_1[ind, 0], pred_ss_1[ind, 1],\n",
    "            pred_ss_1[ind, 2]))\n",
    "        fp.write('\\n')\n",
    "    fp.close()\n",
    "    return SS_1, pred_ss_1, pred_asa_1, theta, tau, phi, psi\n",
    "\n",
    "\n",
    "def main(list_params, pssm_file, outfile, out_suffix):\n",
    "    basenm = os.path.basename(pssm_file)\n",
    "    if basenm.endswith('.pssm'):\n",
    "        basenm = basenm[:-5]\n",
    "    elif basenm.endswith('.mat'):\n",
    "        basenm = basenm[:-4]\n",
    "\n",
    "    outfile0 = '%s%s.%s' % (outfile, basenm, out_suffix)  #\n",
    "\n",
    "    aa, pssm = read_pssm(pssm_file)\n",
    "    pred1(list_params, aa, pssm, outfile0)\n",
    "\n",
    "\n",
    "def load_NN(nn_filename):\n",
    "    return np.load(nn_filename, mmap_mode=None, allow_pickle=True, fix_imports=True,\n",
    "                   encoding=\"latin1\")  # load in the NN mat file.\n",
    "\n",
    "\n",
    "def pred1(list_params, aa, pssm, outfile0):\n",
    "    list_nn = list_params\n",
    "    phys = get_phys7(aa)\n",
    "    input_feature = window_data(pssm, phys)\n",
    "    ## DO FIRST PREDICTIONS\n",
    "    for it1 in (1, 2, 3):\n",
    "        ofile = outfile0\n",
    "        if it1 < 3: ofile = 'NULL'\n",
    "        dict_nn = list_nn[it1 - 1]\n",
    "        res1 = run_iter(dict_nn, input_feature, aa, ofile)\n",
    "        if it1 == 3: break\n",
    "        ## feature after 1st iteration\n",
    "        SS_1, pred_ss_1, pred_asa_1, theta, tau, phi, psi = res1\n",
    "        tt_input = np.sin(np.concatenate((np.radians(theta), np.radians(tau)), axis=1)) / 2 + 0.5\n",
    "        tt_input = np.concatenate(\n",
    "            (tt_input, np.cos(np.concatenate((np.radians(theta), np.radians(tau)), axis=1)) / 2 + 0.5), axis=1)\n",
    "        pp_input = np.sin(np.concatenate((np.radians(phi), np.radians(psi)), axis=1)) / 2 + 0.5\n",
    "        pp_input = np.concatenate(\n",
    "            (pp_input, np.cos(np.concatenate((np.radians(phi), np.radians(psi)), axis=1)) / 2 + 0.5), axis=1)\n",
    "        ttpp_input = np.concatenate((tt_input, pp_input), axis=1)\n",
    "        input_feature = window_data(pssm, phys, pred_ss_1, pred_asa_1, ttpp_input)\n",
    "    return\n",
    "\n",
    "\n",
    "def Splitpp(f):\n",
    "    id = []\n",
    "    seq = []\n",
    "    pos = []\n",
    "    site = []\n",
    "    # pot = []\n",
    "    st = ''\n",
    "    i = 0\n",
    "    # j = 0\n",
    "    # k = 0\n",
    "    with open('../../' + f, 'r') as fout:\n",
    "        for line in fout:\n",
    "            line = line.rstrip()\n",
    "            i = i + 1\n",
    "            if line.startswith('>') or '|' in line:\n",
    "                if i != 1:\n",
    "                    st = st.upper()\n",
    "                    st = st.replace('U', '*')\n",
    "                    seq.append(st)\n",
    "                    st = ''\n",
    "                if '|' in line:\n",
    "                    id.append(line.split('|')[1])\n",
    "                elif ' ' in line:\n",
    "                    id.append(line.split('>')[1].split(' ')[0])\n",
    "                elif '\\t' in line:\n",
    "                    id.append(line.split('>')[1].split('\\t')[0])\n",
    "                else:\n",
    "                    id.append(line.split('>')[1])\n",
    "            else:\n",
    "                st = st + line\n",
    "    st = st.upper()\n",
    "    st = st.replace('U', '*')\n",
    "    seq.append(st)\n",
    "    for i, k in enumerate(seq):\n",
    "        po = find_all_index(k, 'K')\n",
    "        pos.append(po)\n",
    "        sit = []\n",
    "        for j, p in enumerate(po):\n",
    "            if p >= 30 and (len(k) - p - 1) < 30:\n",
    "                s = k[p - 30:]\n",
    "                for i in range(30 - (len(k) - p - 1)):\n",
    "                    s = s + \"*\"\n",
    "            elif p < 30 and (len(k) - p - 1) < 30:\n",
    "                s = k[:]\n",
    "                for i in range(30 - (len(k) - p - 1)):\n",
    "                    s = s + \"*\"\n",
    "                for i in range(30 - (p)):\n",
    "                    s = \"*\" + s\n",
    "            elif p < 30 and (len(k) - p - 1) >= 30:\n",
    "                s = k[:p + 31]\n",
    "                for i in range(30 - (p)):\n",
    "                    s = \"*\" + s\n",
    "            else:\n",
    "                s = k[p - 30:p + 31]\n",
    "            sit.append(s)\n",
    "        site.append(sit)\n",
    "    list0, list30, list20, list10, pid, ps = [], [], [], [], [], []\n",
    "    dic = f.split('.')[0][9:]\n",
    "    if not os.path.exists('123/' + dic):\n",
    "        os.makedirs('123/' + dic)\n",
    "    os.chdir('123/' + dic)\n",
    "    if not os.path.exists('asa_result'):\n",
    "        os.makedirs('asa_result')\n",
    "    if not os.path.exists('ZFilepathPSSM'):\n",
    "        os.makedirs('ZFilepathPSSM')\n",
    "    if not os.path.exists('ZFilepathresult'):\n",
    "        os.makedirs('ZFilepathresult')\n",
    "    with open('peptide.txt', 'w') as fout:\n",
    "        for i, d in enumerate(id):\n",
    "            for j, s in enumerate(site[i]):\n",
    "                list30.append(s)\n",
    "                list20.append(s[10:-10])\n",
    "                list10.append(s[20:-20])\n",
    "                pid.append(d)\n",
    "                ps.append(pos[i][j] + 1)\n",
    "                fout.write(s + '\\t' + d + '\\t' + str(pos[i][j] + 1) + '\\n')\n",
    "    list0.append(list30)\n",
    "    list0.append(list20)\n",
    "    list0.append(list10)\n",
    "    os.chdir('../../')\n",
    "    return list0, pid, ps, dic\n",
    "\n",
    "\n",
    "def acf(list30):  # acl,aal\n",
    "    # import pandas as pd\n",
    "    # wt.write(time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':acf00'+'\\n')\n",
    "    global acl, aal, acn, aan, acsl, aasl\n",
    "    pos = DataFrame(list30)\n",
    "    all_ = pos\n",
    "    # with open('../aaindex1.txt', 'r') as fout:\n",
    "    #    line=fout.readline()\n",
    "    #    line=line.rstrip()[5:]\n",
    "    #    aalist=line.split('\\t')\n",
    "    ll, j = 0, 0\n",
    "    na = {}  # AAindex字典：特征->氨基酸对应值\n",
    "    vvl = []  # top10特征名字列表,用于在na字典中搜索\n",
    "    with open('top10.txt', 'r') as fout:\n",
    "        line = fout.readline()\n",
    "        line = line.rstrip()[5:]\n",
    "        aalist = line.split('\\t')  # aa名称列表\n",
    "        for line in fout:\n",
    "            ll = ll + 1\n",
    "            line = line.rstrip()\n",
    "            na[line.split('\\t')[0]] = line.split('\\t')[1:]\n",
    "            vvl.append(line.split('\\t')[0])\n",
    "\n",
    "    # wt.write(time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':acf100')\n",
    "    # with open('../aaindex1.txt', 'r') as fout:\n",
    "    #    line=fout.readline()\n",
    "    #    line=line.rstrip()[5:]\n",
    "    #    aalist=line.split('\\t')\n",
    "    #    for line in fout:\n",
    "    #        j=j+1\n",
    "    #        line=line.rstrip()\n",
    "    #        na[j]=line.split('\\t')[1:]\n",
    "    # vvl1.sort(reverse=True)\n",
    "    # vvl = []\n",
    "    # con=range(11,31)\n",
    "    # ww=open('top10.txt','w')\n",
    "    # ww.write('name\\t'+'\\t'.join(aalist)+'\\n')\n",
    "    # for co in (range(30)):\n",
    "    #     if co + 1 in con:\n",
    "    #         llo = 0\n",
    "    #     else:\n",
    "    #         vvl.append(vvl1[co])\n",
    "    #         ww.write(str(vvlist[vvl1[co]])+'\\t'+'\\t'.join(na[vvlist[vvl1[co]]])+'\\n')\n",
    "\n",
    "    def doc2num1(ss):\n",
    "        sss, AAindex_Encode = [], []\n",
    "        ss = ss.replace('*', '0')\n",
    "        ss = ss.replace('X', '0')\n",
    "        ss = ss.replace('B', '0')\n",
    "        ss = ss.replace('U', '0')\n",
    "        for k in vvl:\n",
    "            s = list(ss)\n",
    "            for i, ii in enumerate(aalist):\n",
    "                s = [(na[k][i]) if x == ii else x for x in s]\n",
    "            s = [float(x) for x in s]\n",
    "            sss = sss + s\n",
    "        return sss\n",
    "\n",
    "    def doc2num(ss):  # ss=all_[0]=usp序列\n",
    "        # ss=ss[20:-20]\n",
    "        AAindex_Encode = []\n",
    "        ss = ss.replace('*', '0')\n",
    "        ss = ss.replace('X', '0')\n",
    "        ss = ss.replace('B', '0')\n",
    "        ss = ss.replace('U', '0')\n",
    "        for k in vvl:\n",
    "            s = list(ss)  # 将ss中的序列从dataframe转化为list存在s中\n",
    "            for i, ii in enumerate(aalist):  # enumerate枚举，i是索引，ii是值：此处，i是aa名称的索引，ii是aa名称\n",
    "                s = [(na[k][i]) if x == ii else x for x in s]  # k:vvl（特征） + i:aalist（aa） 一一对应\n",
    "            s = [float(x) for x in s]\n",
    "            AAindex_Encode.append(s)\n",
    "        ACF_Encode = np.zeros((np.array(AAindex_Encode).shape[0], np.array(AAindex_Encode).shape[1]))\n",
    "        for i, seq in enumerate(AAindex_Encode):\n",
    "            for k, kv in enumerate(ss):\n",
    "                sumValue = 0\n",
    "                for j in range(0, len(seq) - k):\n",
    "                    singleValue = seq[j] * seq[j + k]\n",
    "                    sumValue = sumValue + singleValue\n",
    "                ACF_Encode[i][k] = round(sumValue / (len(seq) - k), 2)\n",
    "        ACF_Encode = ACF_Encode.flatten().tolist()\n",
    "        return ACF_Encode\n",
    "\n",
    "    # wt.write(time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':acf11'+'\\n')\n",
    "    all_['doc2num'] = all_[0].apply(lambda ss: doc2num(ss))  # 将存在all_[0]中的序列以ss的名字导入doc2num，每次取一条序列\n",
    "    # wt.write(time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':acf12'+'\\n')\n",
    "    all_['doc2num1'] = all_[0].apply(lambda ss: doc2num1(ss))  # 将存在all_[0]中的序列以ss的名字导入doc2num1，每次取一条序列\n",
    "    # wt.write(time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':acf13'+'\\n')\n",
    "    # for i in list(all_['doc2num']):\n",
    "    #     print(len(i))\n",
    "    xy = np.array(list(all_['doc2num']), dtype=np.float64)\n",
    "    x2 = xy.tolist()\n",
    "    x = np.array(list(all_['doc2num1']), dtype=np.float64)\n",
    "    x3 = x.tolist()\n",
    "\n",
    "    # acl,aal=acf(list0[0])\n",
    "    acl, aal = x2, x3\n",
    "    # aal = x3\n",
    "    # acn=acl\n",
    "    # if  spes==9:aan=[a[100:-100] for a in aal]\n",
    "    # elif spes==0 or s==8:aan=[a[200:-200] for a in aal]\n",
    "    # else:aan=aal\n",
    "    # acsl=ls(acl,'ACF')\n",
    "    # aasl=ls(aal,'AAindex')\n",
    "    return acl, aal  # acf,AAindex\n",
    "    # return x3\n",
    "\n",
    "\n",
    "def pssm1(list10, dic, protname):\n",
    "    global ppf\n",
    "    ppf = {}\n",
    "    # pp=open('./pssm/pssm.txt','r')\n",
    "    # for l in pp:\n",
    "    #     l=l.rstrip().split('\\t')\n",
    "    #     ppf[l[0]]=l[1]+'\\t'+l[2]+'\\t'+l[3]\n",
    "    pnlist = list10\n",
    "    # sp2 = ['all', 'Homo_sapiens', 'Mus_musculus', 'Saccharomyces_cerevisiae', 'Oryza_sativa', 'Rattus_norvegicus',\n",
    "    #        'Escherichia_coli', 'Solanum_lycopersicum',\n",
    "    #        'Bacillus_subtilis', 'Brachypodium_distachyon', 'Corynebacterium_glutamicum', 'Mycobacterium_tuberculosis',\n",
    "    #        'Toxoplasma_gondii', 'Vibrio_parahaemolyticus']\n",
    "    # sp2=['all']\n",
    "    # for i in sp2:\n",
    "    #     if i==sp2[spe]:continue\n",
    "    #     if not os.path.exists('./pssm/'+i+'ps.txt'):continue\n",
    "    #     pp = open('./pssm/'+i+'ps.txt', 'r')\n",
    "    #     for l in pp:\n",
    "    #         l = l.rstrip().split('\\t')\n",
    "    #         ppf[l[0]] = l[1] + '\\t' + './pssm/'+l[2] + '\\t' +'./pssm/'+ l[3]\n",
    "    # for i in sp2:\n",
    "    #     if i == sp2[spe]: continue\n",
    "    #     if not os.path.exists('./pssm/aa' + i + '.txt'):continue\n",
    "    #     pp = open('./pssm/aa' + i + '.txt', 'r')\n",
    "    #     for l in pp:\n",
    "    #         if not l.count('\\t')==3:continue\n",
    "    #         l = l.rstrip().split('\\t')\n",
    "    #         ppf[l[0]] = l[1] + '\\t' + l[2] + '\\t' + l[3]\n",
    "    with open(dic + '/Protein.txt', 'w') as fout:\n",
    "        for it, iter in enumerate(pnlist):\n",
    "            fout.write('>sp|' + str(protname[it]) + '|' + '\\n')\n",
    "            fout.write(iter + \"\\n\")\n",
    "    ProSeq = dic + \"/Protein.txt\"\n",
    "    OutDir = dic + '/ZFilepathresult'\n",
    "    PSSMDir = dic + '/ZFilepathPSSM'\n",
    "    DBname = dic + '/ZDB/DB'\n",
    "    GetPSSM(ProSeq, OutDir, PSSMDir, DBname)\n",
    "    # time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )+':pssm1'+'\\n')\n",
    "\n",
    "\n",
    "#\n",
    "# def pssm2(list10,dic,strat):\n",
    "#     global ppf\n",
    "#     ppf={}\n",
    "#     pp=open('../../pssm/pssm.txt','r')\n",
    "#     for l in pp:\n",
    "#         l=l.rstrip().split('\\t')\n",
    "#         ppf[l[0]]=l[1]+'\\t'+l[2]+'\\t'+l[3]\n",
    "#     pnlist = list10\n",
    "#     with open(dic+'/Protein1.txt','w') as fout:\n",
    "#             for it,iter in enumerate(pnlist):\n",
    "#                 fout.write('>sp|'+str(it+strat)+'|'+'\\n')\n",
    "#                 fout.write(iter+\"\\n\")\n",
    "#     ProSeq = dic+\"/Protein1.txt\"\n",
    "#     OutDir = dic+'/ZFilepathresult'\n",
    "#     PSSMDir=dic+'/ZFilepathPSSM'\n",
    "#     DBname = '../ZDB/DB'\n",
    "#     GetPSSM(ProSeq,OutDir,PSSMDir,DBname)\n",
    "# def pssm3(list10,dic,strat):\n",
    "#     global ppf\n",
    "#     ppf={}\n",
    "#     pp=open('../../pssm/pssm.txt','r')\n",
    "#     for l in pp:\n",
    "#         l=l.rstrip().split('\\t')\n",
    "#         ppf[l[0]]=l[1]+'\\t'+l[2]+'\\t'+l[3]\n",
    "#     pnlist = list10\n",
    "#     with open(dic+'/Protein2.txt','w') as fout:\n",
    "#             for it,iter in enumerate(pnlist):\n",
    "#                 fout.write('>sp|'+str(it+strat)+'|'+'\\n')\n",
    "#                 fout.write(iter+\"\\n\")\n",
    "#     ProSeq = dic+\"/Protein2.txt\"\n",
    "#     OutDir = dic+'/ZFilepathresult'\n",
    "#     PSSMDir=dic+'/ZFilepathPSSM'\n",
    "#     DBname = '../ZDB/DB'\n",
    "#     GetPSSM(ProSeq,OutDir,PSSMDir,DBname)\n",
    "def ss1(list10, dic):\n",
    "    global sn, asal, ssl, asan, ssn, asasl, sssl\n",
    "    OldPSMMdir = dic + '/ZFilepathPSSM'\n",
    "    origin_outfile = dic + '/asa_result'\n",
    "    detial_pssm = OldPSMMdir + '/'\n",
    "    outfile = origin_outfile + '/'\n",
    "    if not os.path.exists(outfile):\n",
    "        os.makedirs(outfile)\n",
    "    next_listfile = os.listdir(detial_pssm)\n",
    "    # next_listfile.sort(key=lambda x: int(x[0:-5]))\n",
    "    for i, pssm_file in enumerate(next_listfile):\n",
    "        if os.path.exists(outfile + pssm_file.split('.')[0] + '.txt'): continue\n",
    "        nndir = r'./SS/'\n",
    "        dict1_nn = load_NN(nndir + 'pp1.npz')\n",
    "        dict2_nn = load_NN(nndir + 'pp2.npz')\n",
    "        dict3_nn = load_NN(nndir + 'pp3.npz')\n",
    "        list_nn = (dict1_nn, dict2_nn, dict3_nn)\n",
    "        main(list_nn, detial_pssm + '/' + pssm_file, outfile, r'txt')\n",
    "    sn, asal, ssl, btal, namesout = ss(dic)\n",
    "    # print(asal)\n",
    "    # asan, ssn = asal, ssl\n",
    "    # asasl =ls(asal, 'ASA')\n",
    "    # sssl =ls(ssl, 'SS')\n",
    "    return asal, ssl, btal, namesout  # ASA, SS, BTA\n",
    "\n",
    "\n",
    "# def pssm(dic,hg):\n",
    "#     global pn, pssl,psn\n",
    "#     OldPSMMdir = dic+'/ZFilepathPSSM'#输出\n",
    "#     FinPSSM, num =StandardpPSSM(OldPSMMdir)\n",
    "#     pn, psl =num, FinPSSM\n",
    "#     psn = psl\n",
    "#     # pssl = ls(psl, 'PSSM')\n",
    "#     #return num, FinPSSM\n",
    "\n",
    "def ss(dic):\n",
    "    OldPSMMdir = dic + '/asa_result'  # 输出\n",
    "    FinPSSM, FinPSSM1, FinPSSM2, num, namesout = psStandardpPSSM(OldPSMMdir)\n",
    "    xy = np.array(list(FinPSSM), dtype=np.float64)\n",
    "    x2 = xy.tolist()\n",
    "    xy1 = np.array(list(FinPSSM1), dtype=np.float64)\n",
    "    x3 = xy1.tolist()\n",
    "    xy2 = np.array(list(FinPSSM2), dtype=np.float64)\n",
    "    x4 = xy2.tolist()\n",
    "    return num, x2, x3, x4, namesout\n",
    "\n",
    "\n",
    "# 氨基酸对组成 0、1、2、3\n",
    "def kmors(list10, km, m='l'):\n",
    "    # global kmn\n",
    "    pos = DataFrame(list10)\n",
    "    all_ = pos\n",
    "    aalist = []\n",
    "    if m == 'd':\n",
    "        ablist = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "    else:\n",
    "        ablist = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X',\n",
    "                  'Y']\n",
    "    for aa in ablist:\n",
    "        for bb in ablist:\n",
    "            aalist.append(aa + bb)\n",
    "\n",
    "    def doc2num(s):\n",
    "        ssss = []\n",
    "        for k in range(km):\n",
    "            alist = []\n",
    "            for i, a in enumerate(s):\n",
    "                if i + k + 1 < len(s):\n",
    "                    alist.append(a + s[i + k + 1])\n",
    "                else:\n",
    "                    continue\n",
    "            ss = [float(alist.count(i)) for i in aalist]\n",
    "            ssss = ssss + ss[:]\n",
    "        return list(ssss)\n",
    "\n",
    "    all_['doc2num'] = all_[0].apply(lambda s: doc2num(s))\n",
    "    x = np.array(list(all_['doc2num']), dtype=np.int64)\n",
    "    x2 = x.tolist()\n",
    "    return x2\n",
    "\n",
    "\n",
    "# 氨基酸组成\n",
    "def aac1(list10):\n",
    "    pos = DataFrame(list10)\n",
    "    all_ = pos\n",
    "    aalist = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "    ll = len(list10[0])\n",
    "\n",
    "    def doc2num(s):\n",
    "        s = [float(s.count(i) / ll) for i in aalist]\n",
    "        s = s[:]\n",
    "        return list(s)\n",
    "\n",
    "    all_['doc2num'] = all_[0].apply(lambda s: doc2num(s))\n",
    "\n",
    "    x = np.array(list(all_['doc2num']), dtype=np.float64)\n",
    "    x2 = x.tolist()\n",
    "    return x2\n",
    "\n",
    "\n",
    "# list中肽段转为2进制 d控制是否序列中有U\n",
    "def be1(list10, d):\n",
    "    # import pandas as pd\n",
    "\n",
    "    all_ = DataFrame(list10)\n",
    "    abc = Series(range(0, 21),\n",
    "                 index=['K', 'L', 'A', 'E', 'V', 'G', 'S', 'D', 'I', 'T', 'R', '*', 'P', 'Q', 'N', 'F', 'Y', 'M', 'H',\n",
    "                        'C', 'W'])\n",
    "    if d == 0: abc = Series(range(0, 22),\n",
    "                            index=['K', 'L', 'A', 'E', 'V', 'G', 'S', 'D', 'I', 'T', 'R', '*', 'P', 'Q', 'N', 'F', 'Y',\n",
    "                                   'M', 'H', 'C', 'W', 'U'])\n",
    "    abc[:] = range(len(abc))\n",
    "    word_set = set(abc.index)\n",
    "\n",
    "    def doc2num(s):\n",
    "        s = s.replace('X', '*')\n",
    "        s = s.replace('B', '*')\n",
    "        s = [i for i in s if i in word_set]\n",
    "        return list(abc[s])\n",
    "\n",
    "    all_['doc2num'] = all_[0].apply(lambda s: doc2num(s))\n",
    "\n",
    "    x = np.array(list(all_['doc2num']), dtype=np.int64)\n",
    "    gen_matrix = lambda z: (to_categorical(z, len(abc)).flatten())\n",
    "\n",
    "    def data_generator(data, batch_size):\n",
    "        batches = [range(batch_size * i, min(len(data), batch_size * (i + 1))) for i in\n",
    "                   range(int(len(data) / batch_size + 1))]\n",
    "        while True:\n",
    "            for i in batches:\n",
    "                xx = np.array(list(map(gen_matrix, data[i])))\n",
    "            return (xx)\n",
    "\n",
    "    x = data_generator(x[:], len(x) + 1)\n",
    "    bin = x.tolist()\n",
    "    return bin\n",
    "\n",
    "\n",
    "# list:[k-mer]\n",
    "def gps(list):\n",
    "    global gpn\n",
    "    for i, ii in enumerate(list):\n",
    "        ii = ii.replace('U', '*')\n",
    "        list[i] = ii\n",
    "\n",
    "    # from keras.models import load_model\n",
    "\n",
    "    def generateMMData(querylist, plist, pls_weight, mm_weight, loo=True, positive=False):\n",
    "        gp = GpsPredictor(plist, pls_weight, mm_weight)\n",
    "\n",
    "        d = []\n",
    "\n",
    "        for query_peptide in querylist:\n",
    "            d.append(gp.generateMMdata(query_peptide, loo).tolist())\n",
    "        return d\n",
    "\n",
    "    mm_weight = readweight('BLOSUM62R.txt')  # 1th is intercept\n",
    "\n",
    "    ll = len(list[0])\n",
    "    gpn = generateMMData(list, list, np.repeat(1, ll), mm_weight, loo=False, positive=False)\n",
    "    # plist = readPeptide('./Protein/0.peptide',int(ll/2))\n",
    "\n",
    "    # gpn = generateMMData(list, plist,np.repeat(1, ll), mm_weight, loo=False, positive=False)# for p in nlist]\n",
    "    return gpn\n",
    "\n",
    "\n",
    "class GpsPredictor(object):\n",
    "    def __init__(self, plist, pls_weight, mm_weight):\n",
    "        '''\n",
    "        initial GPS predictor using positive training set, pls_weight vector and mm_weight vector\n",
    "        :param plist: (list) positive peptides list\n",
    "        :param pls_weight:  (list) pls_weight vector\n",
    "        :param mm_weight:   (list) mm_weight vector\n",
    "        '''\n",
    "        self.alist = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y',\n",
    "                      'V', 'B', 'Z', 'X', '*']\n",
    "        self.plist = plist\n",
    "        self.pls_weight = np.array(pls_weight).flatten()\n",
    "        self.mm_weight = np.array(mm_weight).flatten()\n",
    "\n",
    "        self.__count_matrix = self._plist_index()\n",
    "        self.__mm_matrix, self.__mm_intercept = self._mmweight2matrix()\n",
    "\n",
    "    def predict(self, query_peptide, loo=False):\n",
    "        '''\n",
    "        return the gps score for the query peptide\n",
    "        :param query_peptide: (str) query peptide\n",
    "        :param loo: (bool) if true, count_matrix will minus 1 according to the amino acid in each position in query peptide\n",
    "        :return: gps score\n",
    "        '''\n",
    "        count_clone = self.__count_matrix * len(self.plist)\n",
    "        matrix = np.zeros_like(self.__count_matrix)\n",
    "        for i, a in enumerate(query_peptide):\n",
    "            if a not in self.alist: a = 'C'\n",
    "            if loo: count_clone[i, self.alist.index(a)] -= 1\n",
    "            matrix[i, :] = self.__mm_matrix[self.alist.index(a), :]\n",
    "        rm_num = 1 if loo else 0\n",
    "        pls_count_matrix = (count_clone.T * self.pls_weight).T / (len(self.plist) - rm_num)\n",
    "        return np.sum(matrix * pls_count_matrix) + self.__mm_intercept\n",
    "\n",
    "    def generatePLSdata(self, query_peptide, loo=False):\n",
    "        '''\n",
    "        generate the pls vector of query peptide\n",
    "        :param query_peptide: (str) query peptide\n",
    "        :param loo: (bool) if true, the count_matrix will minus 1 according to the amino acid in each position in query peptide\n",
    "        :return: (np.ndarray) the vector of feature for each position\n",
    "        '''\n",
    "        count_clone = self.__count_matrix * len(self.plist)\n",
    "        matrix = np.zeros_like(count_clone)\n",
    "        for i, a in enumerate(query_peptide):\n",
    "            if a not in self.alist: a = 'C'\n",
    "            if loo:\n",
    "                count_clone[i, self.alist.index(a)] -= 1\n",
    "\n",
    "            matrix[i, :] = self.__mm_matrix[self.alist.index(a), :]\n",
    "        rm_num = 1 if loo else 0\n",
    "        count_clone = (count_clone.T * self.pls_weight).T\n",
    "        return np.sum(matrix * count_clone / (len(self.plist) - rm_num), 1)\n",
    "\n",
    "    def generateMMdata(self, query_peptide, loo=False):\n",
    "        count_clone = self.__count_matrix * len(self.plist)\n",
    "\n",
    "        indicator_matrix = np.zeros_like(count_clone)\n",
    "        for i, a in enumerate(query_peptide):\n",
    "            if a not in self.alist: a = 'C'\n",
    "            if loo: count_clone[i, self.alist.index(a)] -= 1\n",
    "            indicator_matrix[i, self.alist.index(a)] = 1\n",
    "\n",
    "        rm_num = 1 if loo else 0\n",
    "\n",
    "        count_clone /= (len(self.plist) - rm_num)\n",
    "\n",
    "        pls_count_matrix = (count_clone.T * self.pls_weight).T\n",
    "\n",
    "        m = np.dot(indicator_matrix.T, pls_count_matrix) * self.__mm_matrix\n",
    "\n",
    "        m += m.T\n",
    "\n",
    "        np.fill_diagonal(m, np.diag(m) / float(2))\n",
    "\n",
    "        iu1 = np.triu_indices(m.shape[0])\n",
    "\n",
    "        return m[iu1]\n",
    "\n",
    "    def getcutoff(self, randompeplist, sp=[0.98, 0.95, 0.85]):\n",
    "        '''\n",
    "        return cutoffs using 10000 random peptides as negative\n",
    "        :param randompeplist: (list) random generated peptides\n",
    "        :param sp: (float list) sp to be used for cutoff setting\n",
    "        :return: (float list) cutoffs, same lens with sp\n",
    "        '''\n",
    "        rand_scores = sorted([self.predict(p) for p in randompeplist])\n",
    "        cutoffs = np.zeros(len(sp))\n",
    "        for i, s in enumerate(sp):\n",
    "            index = np.floor(len(rand_scores) * s).astype(int)\n",
    "            cutoffs[i] = rand_scores[index]\n",
    "        return cutoffs\n",
    "\n",
    "    def _plist_index(self):\n",
    "        '''\n",
    "        return the amino acid frequency on each position, row: position, column: self.alist, 61 x 24\n",
    "        :return: count matrix\n",
    "        '''\n",
    "        n, m = len(self.plist[0]), len(self.alist)\n",
    "        count_matrix = np.zeros((n, m))\n",
    "        for i in range(n):\n",
    "            for p in self.plist:\n",
    "                count_matrix[i][self.alist.index(p[i])] += 1\n",
    "        return count_matrix / float(len(self.plist))\n",
    "\n",
    "    def _mmweight2matrix(self):\n",
    "        '''\n",
    "        convert matrix weight vector to similarity matrix, 24 x 24, index order is self.alist\n",
    "        :return:\n",
    "        '''\n",
    "        aalist = self.getaalist()\n",
    "        mm_matrix = np.zeros((len(self.alist), len(self.alist)))\n",
    "        for n, d in enumerate(aalist):\n",
    "            value = self.mm_weight[n + 1]  # mm weight contain intercept\n",
    "            i, j = self.alist.index(d[0]), self.alist.index(d[1])\n",
    "            mm_matrix[i, j] = value\n",
    "            mm_matrix[j, i] = value\n",
    "        return mm_matrix, self.mm_weight[0]\n",
    "\n",
    "    def getaalist(self):\n",
    "        '''return aa-aa list\n",
    "        AA: 0\n",
    "        AR: 1\n",
    "        '''\n",
    "        aa = [self.alist[i] + self.alist[j] for i in range(len(self.alist)) for j in range(i, len(self.alist))]\n",
    "        return aa\n",
    "\n",
    "def check():\n",
    "    print('-------checking-------')\n",
    "    global namelist, ACF, AAindex, binary, gpn, CKSAAPs, PseAAC, ASA, SS, BTA\n",
    "    i = 0\n",
    "    while i < len(namelist):\n",
    "        print(namelist[i])\n",
    "        pssmfile = r'./ZFilepathPSSM/' + str(namelist[i]) + r'.pssm'\n",
    "        if not os.path.exists(pssmfile):\n",
    "            del namelist[i]\n",
    "            del ACF[i]\n",
    "            del AAindex[i]\n",
    "            del binary[i]\n",
    "            del gpn[i]\n",
    "            del CKSAAPs[i]\n",
    "            del PseAAC[i]\n",
    "            del ASA[i]\n",
    "            del SS[i]\n",
    "            del BTA[i]\n",
    "            i -= 1\n",
    "        i += 1\n",
    "\n",
    "def storage10features(storehouse, namelist, acf, aaindex, obc, gps, cksaap, pseaac, asa, ss, bta,\n",
    "                      pssmframe, label):  # all of them are lists\n",
    "    if label == 0:\n",
    "        storehouse = storehouse + '10features_for_negative_data/'\n",
    "    elif label == 1:\n",
    "        storehouse = storehouse + '10features/'\n",
    "    else:\n",
    "        storehouse = storehouse + '10features_for_experiment/'\n",
    "    if not os.path.exists(storehouse):\n",
    "        os.makedirs(storehouse)\n",
    "    with open(storehouse + 'peptides.txt', mode='w') as f1:\n",
    "        for name in namelist:\n",
    "            if name in pepdic.keys():\n",
    "                f1.write(name + '\\n')\n",
    "\n",
    "    def storefeature(name, featurename, feature):\n",
    "        if not os.path.exists(storehouse + featurename):\n",
    "            os.makedirs(storehouse + featurename)\n",
    "        with open(storehouse + featurename + '/' + name + '.' + str.lower(featurename), mode='w') as file:\n",
    "            for fea in feature:\n",
    "                file.write(str(fea) + '\\t')\n",
    "            file.write('\\n')\n",
    "\n",
    "    for iter, item in enumerate(namelist):  # iter[index] item[pepname]\n",
    "        if item in pepdic.keys():\n",
    "            storefeature(item, 'ACF', acf[iter])\n",
    "            storefeature(item, 'AAINDEX', aaindex[iter])\n",
    "            storefeature(item, 'OBC', obc[iter])\n",
    "            storefeature(item, 'GPS', gps[iter])\n",
    "            storefeature(item, 'CKSAAP', cksaap[iter])\n",
    "            storefeature(item, 'PSEAAC', pseaac[iter])\n",
    "            #storefeature(item, 'ASA', asa[iter])\n",
    "            #storefeature(item, 'SS', ss[iter])\n",
    "            #storefeature(item, 'BTA', bta[iter])\n",
    "            #storefeature(item, 'PSSM', pssmframe[iter])\n",
    "    namelist1=list(pepdic.keys()) \n",
    "    for iter, item in enumerate(namelist1):  \n",
    "        if item in pepdic.keys(): \n",
    "            print(item)\n",
    "            print(iter)\n",
    "            storefeature(item, 'ASA', ASA[iter]) \n",
    "            storefeature(item, 'SS', SS[iter]) \n",
    "            storefeature(item, 'BTA', BTA[iter]) \n",
    "            storefeature(item, 'PSSM', pssmframe[iter])\n",
    "\n",
    "def get10features(fileplace):\n",
    "    with open(fileplace + '/negative_peps.txt', mode='r') as f1:\n",
    "        pepnames = f1.read().rstrip().split('\\n')\n",
    "\n",
    "    def getfeatures(fileplace, featuretype, namelist):\n",
    "        feature = []\n",
    "        for name in namelist:\n",
    "            with open(fileplace + featuretype + '/' + name + '.' + str.lower(featuretype), mode='r') as file:\n",
    "                fea = file.read().rstrip().split('\\t')\n",
    "                feature.append(fea)\n",
    "        return feature\n",
    "\n",
    "    ACF = getfeatures(fileplace, 'ACF', pepnames)\n",
    "    AAINDEX = getfeatures(fileplace, 'AAINDEX', pepnames)\n",
    "    ASA = getfeatures(fileplace, 'ASA', pepnames)\n",
    "    BTA = getfeatures(fileplace, 'BTA', pepnames)\n",
    "    CKSAAP = getfeatures(fileplace, 'CKSAAP', pepnames)\n",
    "    GPS = getfeatures(fileplace, 'GPS', pepnames)\n",
    "    OBC = getfeatures(fileplace, 'OBC', pepnames)\n",
    "    PSEAAC = getfeatures(fileplace, 'PSEAAC', pepnames)\n",
    "    PSSM = getfeatures(fileplace, 'PSSM', pepnames)\n",
    "    SS = getfeatures(fileplace, 'SS', pepnames)\n",
    "\n",
    "    return pepnames, ACF, AAINDEX, ASA, BTA, CKSAAP, GPS, OBC, PSEAAC, PSSM, SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e476618-8831-4c08-93f1-5d88303d0d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27a3cc-1be0-494e-9d98-5a475ccfd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pepdic:{ID:peptide}\n",
    "outdic = './results'\n",
    "txt = open('./pos_Kcr.txt', mode='r')\n",
    "txt = txt.readlines()\n",
    "pepdic = {}\n",
    "for line in txt:\n",
    "    line = line.rstrip().split('\\t')\n",
    "    pepdic[line[0]] = line[1]\n",
    "namelist=list(pepdic.keys())\n",
    "peplist=list(pepdic.values())\n",
    "\n",
    "ACF, AAindex=acf(peplist)\n",
    "\n",
    "d=1\n",
    "binary=be1(peplist,d)\n",
    "\n",
    "gpn=gps(peplist)\n",
    "\n",
    "km=1\n",
    "CKSAAPs=kmors(peplist,km,m='l')\n",
    "\n",
    "PseAAC=aac1(peplist)\n",
    "\n",
    "pssm1(peplist,outdic ,namelist)\n",
    "\n",
    "ASA, SS, BTA, namesout = ss1(peplist, outdic)\n",
    "\n",
    "bas_feat={}\n",
    "del_list = []\n",
    "for basname in pepdic.keys():\n",
    "    if not os.path.exists(outdic+\"/ZFilepathPSSM/%s.pssm\"%(basname)):\n",
    "        del_list.append(basname)\n",
    "for del_name in del_list:\n",
    "    del pepdic[del_name]\n",
    "for basname in pepdic.keys():\n",
    "    pssm=open(outdic+\"/ZFilepathPSSM/%s.pssm\"%(basname),'r').readlines()[3:24]\n",
    "    bas_feat[basname] = []\n",
    "    for line in pssm:\n",
    "        if line.startswith(' '):\n",
    "            dat=[i for i in line.strip().split(' ')[2:] if i!='']\n",
    "            dat=dat[:20]\n",
    "            bas_feat[basname]+=dat\n",
    "\n",
    "pssmframe=pd.DataFrame.from_dict(bas_feat, orient='index')\n",
    "pssmframe.columns=['pssm~'+str(i) for i in pssmframe.columns]\n",
    "pssmframe=np.array(pssmframe.values).astype(int)\n",
    "\n",
    "print(f\"Length of namelist: {len(namelist)}\")\n",
    "print(f\"Length of ACF: {len(ACF)}\")\n",
    "print(f\"Length of AAindex: {len(AAindex)}\")\n",
    "print(f\"Length of binary: {len(binary)}\")\n",
    "print(f\"Length of gpn: {len(gpn)}\")\n",
    "print(f\"Length of CKSAAPs: {len(CKSAAPs)}\")\n",
    "print(f\"Length of PseAAC: {len(PseAAC)}\")\n",
    "print(f\"Length of ASA: {len(ASA)}\")\n",
    "print(f\"Length of SS: {len(SS)}\")\n",
    "print(f\"Length of BTA: {len(BTA)}\")\n",
    "print(f\"Length of pssmframe: {len(pssmframe)}\")\n",
    "\n",
    "storage10features('./results/', namelist, ACF, AAindex, binary, gpn, CKSAAPs, PseAAC,\n",
    "                              ASA, SS, BTA, pssmframe, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78f920-f5b6-4de7-95b4-383708fb5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pepdic:{ID:peptide}\n",
    "outdic = './results/10experiment/'\n",
    "txt = open('./experiment_sites.txt', mode='r')\n",
    "txt = txt.readlines()\n",
    "pepdic = {}\n",
    "for line in txt:\n",
    "    line = line.rstrip().split('\\t')\n",
    "    pepdic[line[0]] = line[1]\n",
    "namelist=list(pepdic.keys())\n",
    "peplist=list(pepdic.values())\n",
    "\n",
    "ACF, AAindex=acf(peplist)\n",
    "\n",
    "d=1\n",
    "binary=be1(peplist,d)\n",
    "\n",
    "gpn=gps(peplist)\n",
    "\n",
    "km=1\n",
    "CKSAAPs=kmors(peplist,km,m='l')\n",
    "\n",
    "PseAAC=aac1(peplist)\n",
    "\n",
    "pssm1(peplist,outdic ,namelist)\n",
    "\n",
    "ASA, SS, BTA, namesout = ss1(peplist, outdic)\n",
    "\n",
    "bas_feat={}\n",
    "del_list = []\n",
    "for basname in pepdic.keys():\n",
    "    if not os.path.exists(outdic+\"/ZFilepathPSSM/%s.pssm\"%(basname)):\n",
    "        del_list.append(basname)\n",
    "for del_name in del_list:\n",
    "    del pepdic[del_name]\n",
    "for basname in pepdic.keys():\n",
    "    pssm=open(outdic+\"/ZFilepathPSSM/%s.pssm\"%(basname),'r').readlines()[3:24]\n",
    "    bas_feat[basname] = []\n",
    "    for line in pssm:\n",
    "        if line.startswith(' '):\n",
    "            dat=[i for i in line.strip().split(' ')[2:] if i!='']\n",
    "            dat=dat[:20]\n",
    "            bas_feat[basname]+=dat\n",
    "\n",
    "pssmframe=pd.DataFrame.from_dict(bas_feat, orient='index')\n",
    "pssmframe.columns=['pssm~'+str(i) for i in pssmframe.columns]\n",
    "pssmframe=np.array(pssmframe.values).astype(int)\n",
    "\n",
    "print(f\"Length of namelist: {len(namelist)}\")\n",
    "print(f\"Length of ACF: {len(ACF)}\")\n",
    "print(f\"Length of AAindex: {len(AAindex)}\")\n",
    "print(f\"Length of binary: {len(binary)}\")\n",
    "print(f\"Length of gpn: {len(gpn)}\")\n",
    "print(f\"Length of CKSAAPs: {len(CKSAAPs)}\")\n",
    "print(f\"Length of PseAAC: {len(PseAAC)}\")\n",
    "print(f\"Length of ASA: {len(ASA)}\")\n",
    "print(f\"Length of SS: {len(SS)}\")\n",
    "print(f\"Length of BTA: {len(BTA)}\")\n",
    "print(f\"Length of pssmframe: {len(pssmframe)}\")\n",
    "\n",
    "storage10features('./results/', namelist, ACF, AAindex, binary, gpn, CKSAAPs, PseAAC,\n",
    "                              ASA, SS, BTA, pssmframe, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
