{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be772184-09b2-4c5c-a37b-fe775d68e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import clone_model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4da981-cc69-42a2-a283-f6a43c3bc623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_location, featuretype, modeltype):\n",
    "    t_model = load_model('%s/%s/%s/%s_%s_%d.h5' % (model_location, modeltype, featuretype, str.upper(featuretype),\n",
    "                                                   modeltype,\n",
    "                                                   np.random.randint(1, 6)\n",
    "                                                   ))\n",
    "    return t_model\n",
    "\n",
    "def prepare_data(featuretype, modeltype):\n",
    "    df = pd.read_csv(f'./%s_dataset.csv' % featuretype)\n",
    "    pepnames = df['pepname']\n",
    "    labels = df['label']\n",
    "    if modeltype == 'DNN':\n",
    "        dataset = df.drop(labels=['pepname', 'label'], axis=1)\n",
    "    elif modeltype == 'CNN':\n",
    "        dataset = []\n",
    "        for pepname in pepnames:\n",
    "            img = Image.open(r'./2D_dataset/' + featuretype + r'/' + pepname + r'.png')\n",
    "            img = np.array(img)\n",
    "            img = img / 256\n",
    "            dataset.append(img)\n",
    "    return pepnames, np.array(dataset), labels\n",
    "\n",
    "def balance_your_data(training_labels):\n",
    "    num_pos = 0\n",
    "    num_neg = 0\n",
    "    for training_label in training_labels:\n",
    "        if training_label == 0:\n",
    "            num_neg += 1\n",
    "        else:\n",
    "            num_pos += 1\n",
    "    pos_times = np.float64(num_neg / num_pos)\n",
    "    return {0: 1., 1: pos_times}\n",
    "\n",
    "def proportion(tr_labels):\n",
    "    n_pos = 0\n",
    "    for tr_label in tr_labels:\n",
    "        if tr_label != 0:\n",
    "            n_pos += 1\n",
    "    return np.float64(n_pos / len(tr_labels))\n",
    "\n",
    "from keras import backend as K\n",
    "def reset_keras():\n",
    "    K.clear_session()\n",
    "\n",
    "#feature_list = ['ACF', 'ASA', 'AAINDEX', 'BTA', 'CKSAAP', 'GPS', 'OBC', 'PSEAAC', 'PSSM', 'SS', 'transformer']\n",
    "feature_list = ['transformer']\n",
    "model_list = ['DNN']\n",
    "ROCAUC_scores = []\n",
    "PRAUC_scores = []\n",
    "less_than_50 = []\n",
    "training_time_record = {}\n",
    "max_scores = {}\n",
    "if os.path.exists(r'./transfer/models/DNN/reverse_list.txt'):\n",
    "    with open(r'./transfer/models/DNN/reverse_list.txt', mode='r') as t:\n",
    "        reverse_models = t.readlines()\n",
    "        for i, reverse_model in enumerate(reverse_models):\n",
    "            reverse_models[i] = reverse_model.rstrip()\n",
    "else:\n",
    "    reverse_models = []\n",
    "os.chdir(f'/home/data/t080305/Xiamen/KCR_new/ML/transfer/')\n",
    "for model_type in model_list:\n",
    "    for feature in feature_list:\n",
    "        print('——————————————' + feature + ' ' + model_type + '——————————————')\n",
    "        model1 = get_model('/home/data/t080305/Xiamen/KCR_new/ML/models', feature, model_type)\n",
    "        pepID, data, label = prepare_data(feature, model_type)\n",
    "        ppow = 3\n",
    "        learn_rate = pow(0.1, ppow)\n",
    "        #'''\n",
    "        for layer in model1.layers[:-3]:\n",
    "            # print(layer.name)\n",
    "            layer.trainable = False\n",
    "        #'''\n",
    "        # model1.compile(optimizer=Adam(learning_rate=learn_rate), loss='binary_crossentropy', metrics=['acc'])\n",
    "        ROCAUC_score = 0\n",
    "        PRAUC_score = 0\n",
    "        train_time = 1\n",
    "        split = 5\n",
    "        # ROC_threshold = 0.5  # 0.7 for transformer's DNN ;  0.55 for the rest\n",
    "        # PR_threshold = proportion(label)\n",
    "        max_score = 0\n",
    "        # while ROCAUC_score < ROC_threshold:\n",
    "        # while ROCAUC_score < ROC_threshold or PRAUC_score < PR_threshold:\n",
    "        while train_time < 2:\n",
    "            # if chainname == 'M1':\n",
    "            #    skf = StratifiedKFold(n_splits=2, shuffle=False)\n",
    "            # else:\n",
    "            skf = StratifiedKFold(n_splits=split, shuffle=True, random_state=3)\n",
    "            count = 0\n",
    "            y_label = []\n",
    "            y_score = []\n",
    "            peplist = []\n",
    "            best_models = []\n",
    "\n",
    "            for train_index, test_index in skf.split(data, label):\n",
    "                x_train, x_test = data[train_index], data[test_index]\n",
    "                y_train, y_test = label[train_index], label[test_index]\n",
    "                '''\n",
    "                # 训练数据重采样一次，扩增一倍\n",
    "                index_set = []\n",
    "                for index in train_index:\n",
    "                    if y_train[index] == 1:\n",
    "                        index_set.append(index)\n",
    "                x_enrich_positive = data[index_set]\n",
    "                y_enrich_positive = label[index_set]\n",
    "                for nima in range(1, 9):\n",
    "                    np.append(x_train, x_enrich_positive, axis=0)\n",
    "                    np.append(y_train, y_enrich_positive, axis=0)\n",
    "\n",
    "                xy = list(zip(x_train, y_train))\n",
    "                random.shuffle(xy)\n",
    "                x_train[:], y_train[:] = zip(*xy)\n",
    "                # '''\n",
    "                #'''\n",
    "                if model_type == 'DNN':\n",
    "                    #x_resampled, y_resampled = SMOTE().fit_resample(x_train, y_train)\n",
    "                    x_resampled, y_resampled = ADASYN().fit_resample(x_train, y_train)\n",
    "                else:\n",
    "                    x_train_2D = (x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n",
    "                    x_resampled, y_resampled = SMOTE().fit_resample(x_train_2D, y_train)\n",
    "                    x_resampled = (x_resampled.reshape(x_resampled.shape[0], x_train.shape[1], x_train.shape[2]))\n",
    "                xy = list(zip(x_resampled, y_resampled))\n",
    "                random.shuffle(xy)\n",
    "                x_resampled[:], y_resampled[:] = zip(*xy)\n",
    "                x_train = x_resampled\n",
    "                y_train = y_resampled\n",
    "                # '''\n",
    "\n",
    "                count += 1\n",
    "                y_label.append(list(y_test))\n",
    "                peplist.append(list(pepID[test_index]))\n",
    "\n",
    "                model = clone_model(model1)\n",
    "                model.compile(optimizer=Adam(learning_rate=learn_rate), loss='binary_crossentropy', metrics=['acc'])\n",
    "                '''\n",
    "                model.fit(x_train, y_train, epochs=train_time, batch_size=64, verbose=1,\n",
    "                          class_weight=balance_your_data(y_test)\n",
    "                          )\n",
    "                #'''\n",
    "                model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1,\n",
    "                          class_weight={0: 1, 1: 10}\n",
    "                          )\n",
    "                y_test_score = model.predict(x_test)\n",
    "                y_score.append(list(y_test_score))\n",
    "\n",
    "                best_models.append(model)\n",
    "\n",
    "                # check roc auc score\n",
    "                rocauc_score = roc_auc_score(y_test, y_test_score)\n",
    "                print(f'第%d个%s的%s模型的ROCAUC分数为：' % (count, feature, model_type),\n",
    "                      rocauc_score)\n",
    "                # check auc score of precision-recall curve\n",
    "                precision, recall, _ = precision_recall_curve(y_test, y_test_score)\n",
    "                prauc_score = auc(recall, precision)\n",
    "                print(f'第%d个%s的%s模型的PRAUC分数为：' % (count, feature, model_type), prauc_score)\n",
    "                reset_keras()\n",
    "\n",
    "            from itertools import chain\n",
    "\n",
    "            peplist1 = []\n",
    "            y_score1 = []\n",
    "            y_label1 = []\n",
    "            peplist = list(chain.from_iterable(peplist))\n",
    "            y_score = list(chain.from_iterable(y_score))\n",
    "            y_label = list(chain.from_iterable(y_label))\n",
    "            for pep in pepID:\n",
    "                peplist1.append(peplist[peplist.index(pep)])\n",
    "                y_score1.append(y_score[peplist.index(pep)])\n",
    "                y_label1.append(y_label[peplist.index(pep)])\n",
    "            ROCAUC_score = roc_auc_score(y_label1, y_score1)\n",
    "            if ROCAUC_score < 0.5:  # reverse scores, record reverse model\n",
    "                if feature not in reverse_models:\n",
    "                    reverse_models.append(feature)\n",
    "                for no, score in enumerate(y_score1):\n",
    "                    y_score1[no] = 1 - score\n",
    "            else:\n",
    "                if feature in reverse_models:\n",
    "                    reverse_models.remove(feature)\n",
    "            ROCAUC_score = roc_auc_score(y_label1, y_score1)\n",
    "\n",
    "            if ROCAUC_score > max_score:\n",
    "                max_score = float(str(ROCAUC_score)[0:4])\n",
    "                max_scores[feature] = max_score\n",
    "                fileplace = f'./models/%s/%s/' % (model_type, feature)\n",
    "                if not os.path.exists(fileplace):\n",
    "                    os.makedirs(fileplace)\n",
    "                for i in range(1, 6):\n",
    "                    best_models[i - 1].save(fileplace + f'%s_%s_%d.h5' % (feature, model_type, i))\n",
    "                df_y = pd.concat([pd.DataFrame(peplist1, columns=['pepname']),\n",
    "                                  pd.DataFrame(y_label1, columns=['label']),\n",
    "                                  pd.DataFrame(y_score1, columns=['score'])], axis=1)\n",
    "                df_y.to_csv(f'./models/%s/%s/%s_y_label&score.csv' % (model_type, feature, feature), index=False)\n",
    "                training_time_record[f'%s_%s' % (feature, model_type)] = train_time\n",
    "\n",
    "            print(f'————————————%s的%s模型的最终ROCAUC分数为：' % (feature, model_type),\n",
    "                  ROCAUC_score, '————————————')\n",
    "\n",
    "            '''\n",
    "            FPR, TPR, _ = roc_curve(y_label1, y_score1)\n",
    "            pyplot.plot(FPR, TPR, marker='.', label=model_type)\n",
    "            pyplot.xlabel('False Positive Rate')\n",
    "            pyplot.ylabel('True Positive Rate')\n",
    "            pyplot.legend()\n",
    "            pyplot.show()\n",
    "            '''\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(y_label1, y_score1)\n",
    "            PRAUC_score = auc(recall, precision)\n",
    "            print(f'————————————%s的%s模型的最终PRAUC分数为：' % (feature, model_type), PRAUC_score,\n",
    "                  '————————————')\n",
    "            '''\n",
    "            if ROCAUC_score < ROC_threshold:\n",
    "            # if PRAUC_score < PR_threshold or ROCAUC_score < ROC_threshold:\n",
    "                train_time += random.randint(1, 10)\n",
    "                # train_time += 1\n",
    "            # learn_rate += 0.0001\n",
    "            if train_time > 100:  # or ROCAUC_score < 0.45:\n",
    "                train_time = 5\n",
    "                model1 = get_model('E:/QD065LPSc/Ksuc/models', feature, model_type)\n",
    "                for layer in model1.layers[:-3]:\n",
    "                    layer.trainable = False\n",
    "            '''\n",
    "            #train_time += random.randint(1, 10)\n",
    "            train_time += 1\n",
    "        ROCAUC_scores.append(ROCAUC_score)\n",
    "        PRAUC_scores.append(PRAUC_score)\n",
    "with open(r'./models/DNN/reverse_list.txt', mode='w') as textfile:\n",
    "    for reverse_model in reverse_models:\n",
    "        textfile.write(reverse_model + '\\n')\n",
    "for le in less_than_50:\n",
    "    print(le)\n",
    "if os.path.exists('./DNN_train_time.csv'):\n",
    "    original_training_time_record = pd.read_csv('./DNN_train_time.csv')\n",
    "    for record_name in training_time_record.keys():\n",
    "        original_training_time_record[record_name] = training_time_record[record_name]\n",
    "    original_training_time_record.to_csv('./DNN_train_time.csv', index=False)\n",
    "else:\n",
    "    pd.DataFrame(training_time_record, index=[0]).to_csv('./DNN_train_time.csv', index=False)\n",
    "for model_type in max_scores.keys():\n",
    "    print(model_type + '      ' + str(max_scores[model_type]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
