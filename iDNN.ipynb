{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945d290-1d9f-45e3-9f54-2f6565e027f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "def auc_11(fileplace):\n",
    "    models = ['DNN']\n",
    "    features = ['ACF', 'ASA', 'AAINDEX', 'BTA', 'CKSAAP', 'GPS', 'OBC', 'PSEAAC', 'PSSM', 'SS', 'transformer']\n",
    "    scorelist = []\n",
    "    \n",
    "    # 读取第一个文件以获得pepname\n",
    "    first_file = fileplace + r'/' + models[0] + r'/' + features[0] + r'/' + features[0] + r'_y_label&score.csv'\n",
    "    df_first = pd.read_csv(first_file)\n",
    "    peptidenames = df_first['pepname']\n",
    "    \n",
    "    # 初始化一个 DataFrame 来保存所有的分数\n",
    "    all_scores = pd.DataFrame(peptidenames, columns=['pepname'])\n",
    "    \n",
    "    # 处理每个文件\n",
    "    for mod in models:\n",
    "        for feature in features:\n",
    "            df = pd.read_csv(fileplace + r'/' + mod + r'/' + feature + r'/' + feature + r'_y_label&score.csv')\n",
    "            # 根据 pepname 进行匹配和添加分数\n",
    "            df = df[df['pepname'].isin(peptidenames)]\n",
    "            df = df[['pepname', 'score']]\n",
    "            all_scores = pd.merge(all_scores, df, on='pepname', how='left', suffixes=('', f'_{feature}'))\n",
    "    \n",
    "    # 将分数列提取出来\n",
    "    score_columns = [col for col in all_scores.columns if col != 'pepname']\n",
    "    \n",
    "    # 提取所有的分数列\n",
    "    scorelist = all_scores[score_columns].values\n",
    "    \n",
    "    return np.array(scorelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6768bdda-28b9-4b89-81ad-86531754ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###用了这个\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def trans_training_DNN(pepID, x, y):\n",
    "    print('\\n')\n",
    "    print('———————————— Training small sample integrated DNN model ————————————')\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    import gc\n",
    "\n",
    "    def reset_keras():\n",
    "        from tensorflow.keras.backend import clear_session\n",
    "        clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "    feature_size = x.shape[1]\n",
    "\n",
    "    # 使用 5 折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    count = 1\n",
    "    y_label = []\n",
    "    y_score = []\n",
    "    peplist = []\n",
    "\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        x_resampled, y_resampled = ADASYN().fit_resample(x_train, y_train)\n",
    "        xy = list(zip(x_resampled, y_resampled))\n",
    "        random.shuffle(xy)\n",
    "        x_resampled[:], y_resampled[:] = zip(*xy)\n",
    "        x_train = x_resampled\n",
    "        y_train = y_resampled\n",
    "        \n",
    "        dnn = get_model(feature_size)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ModelCheckpoint(f'./transfer/models/integrated_DNN/iDNN_{count}.h5', save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "        ]\n",
    "\n",
    "        dnn.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=64,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        y_label.append(list(y_test))\n",
    "        y_test_score = dnn.predict(x_test).flatten()\n",
    "        y_score.append(list(y_test_score))\n",
    "        dnn.save(f'./models/integrated_DNN/iDNN_{count}.h5')\n",
    "        peplist.append(list(pepID[test_index]))\n",
    "\n",
    "        auc_score = roc_auc_score(y_test, y_test_score)\n",
    "        print(f'第 {count} 个模型的AUC分数为：{auc_score}')\n",
    "        count += 1\n",
    "        reset_keras()\n",
    "\n",
    "    from itertools import chain\n",
    "    df_y = pd.concat([\n",
    "        pd.DataFrame(list(chain.from_iterable(peplist)), columns=['pepname']),\n",
    "        pd.DataFrame(list(chain.from_iterable(y_label)), columns=['label']),\n",
    "        pd.DataFrame(list(chain.from_iterable(y_score)), columns=['score'])\n",
    "    ], axis=1)\n",
    "    df_y.to_csv('./transfer/models/integrated_DNN/iDNN_y_label&score.csv', index=False)\n",
    "\n",
    "    AUC_score = roc_auc_score(list(chain.from_iterable(y_label)), list(chain.from_iterable(y_score)))\n",
    "    print(f'———————————— 模型的最终AUC分数为：{AUC_score} ————————————')\n",
    "    return AUC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "eb0a668e-bd03-4172-a7d0-ffd2c5db5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_and_label(fileplace):\n",
    "    df = pd.read_csv(fileplace + 'models/DNN/ASA/ASA_y_label&score.csv')\n",
    "    name = df['pepname']\n",
    "    name = name.values\n",
    "    label = df['label']\n",
    "    label = label.values\n",
    "    return name, label\n",
    "\n",
    "\n",
    "def get_model(size):\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    from tensorflow.keras import Sequential\n",
    "    dnn = Sequential()\n",
    "    dnn.add(Dense(11, input_shape=(size,), bias_initializer='ones', name='Input'))\n",
    "    dnn.add(Dense(128, activation='relu', name='Hidden1'))\n",
    "    dnn.add(layers.Dropout(0.5, name='Dropout1'))\n",
    "    dnn.add(Dense(64, activation='relu', name='Hidden2'))\n",
    "    dnn.add(layers.Dropout(0.5, name='Dropout2'))\n",
    "    dnn.add(Dense(1, activation='sigmoid', name='Output'))\n",
    "    dnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38a889-2510-457c-a73c-4b5c714b9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "###用了这个\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def training_DNN(pepID, x, y):\n",
    "    print('\\n')\n",
    "    print('———————————— Training integrated DNN model ————————————')\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    import gc\n",
    "\n",
    "    def reset_keras():\n",
    "        from tensorflow.keras.backend import clear_session\n",
    "        clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "    feature_size = x.shape[1]\n",
    "\n",
    "    # 使用 5 折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    count = 1\n",
    "    y_label = []\n",
    "    y_score = []\n",
    "    peplist = []\n",
    "\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        dnn = get_model(feature_size)\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "            ModelCheckpoint(f'./models/integrated_DNN/iDNN_{count}.h5', save_best_only=True),\n",
    "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "        ]\n",
    "\n",
    "        dnn.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=64,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        y_label.append(list(y_test))\n",
    "        y_test_score = dnn.predict(x_test).flatten()\n",
    "        y_score.append(list(y_test_score))\n",
    "        dnn.save(f'./models/integrated_DNN/iDNN_{count}.h5')\n",
    "        peplist.append(list(pepID[test_index]))\n",
    "\n",
    "        auc_score = roc_auc_score(y_test, y_test_score)\n",
    "        print(f'第 {count} 个模型的AUC分数为：{auc_score}')\n",
    "        count += 1\n",
    "        reset_keras()\n",
    "\n",
    "    from itertools import chain\n",
    "    df_y = pd.concat([\n",
    "        pd.DataFrame(list(chain.from_iterable(peplist)), columns=['pepname']),\n",
    "        pd.DataFrame(list(chain.from_iterable(y_label)), columns=['label']),\n",
    "        pd.DataFrame(list(chain.from_iterable(y_score)), columns=['score'])\n",
    "    ], axis=1)\n",
    "    df_y.to_csv('./models/integrated_DNN/iDNN_y_label&score.csv', index=False)\n",
    "\n",
    "    AUC_score = roc_auc_score(list(chain.from_iterable(y_label)), list(chain.from_iterable(y_score)))\n",
    "    print(f'———————————— 模型的最终AUC分数为：{AUC_score} ————————————')\n",
    "    return AUC_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4aadeb-8235-4d7f-9c1a-3662f1ba5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-training\n",
    "#'''\n",
    "dataset = auc_11('./models')\n",
    "peplist, labels = get_name_and_label('./')\n",
    "DNN_score = training_DNN(peplist, dataset, labels)\n",
    "#'''\n",
    "\n",
    "# trans-training\n",
    "dataset = auc_11('./transfer/models')\n",
    "peplist, labels = get_name_and_label('./transfer/')\n",
    "DNN_score = trans_training_DNN(peplist, dataset, labels)\n",
    "print('最高分数为：' + str(DNN_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e62960d5-1bd8-4a37-84fe-35e823c2831c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACF特征的DNN模型的rocauc分数为：0.5667040192573356\n",
      "ASA特征的DNN模型的rocauc分数为：0.5682729762899984\n",
      "AAINDEX特征的DNN模型的rocauc分数为：0.6062577447335811\n",
      "BTA特征的DNN模型的rocauc分数为：0.5753143843047972\n",
      "CKSAAP特征的DNN模型的rocauc分数为：0.7250790036937562\n",
      "GPS特征的DNN模型的rocauc分数为：0.6885787042801326\n",
      "OBC特征的DNN模型的rocauc分数为：0.632040666891968\n",
      "PSEAAC特征的DNN模型的rocauc分数为：0.5833451912986249\n",
      "PSSM特征的DNN模型的rocauc分数为：0.6399773512862929\n",
      "SS特征的DNN模型的rocauc分数为：0.5784337702993544\n",
      "transformer特征的DNN模型的rocauc分数为：0.6970300608137714\n"
     ]
    }
   ],
   "source": [
    "# collect the auc scores of 11 DNNs and integrated_DNN's results\n",
    "# '''\n",
    "df_iDNN = pd.read_csv('./transfer/models/integrated_DNN/iDNN_y_label&score.csv')\n",
    "label = df_iDNN['label']\n",
    "score = df_iDNN['score']\n",
    "df_scores = []\n",
    "feature_list = ['ACF', 'ASA', 'AAINDEX', 'BTA', 'CKSAAP', 'GPS', 'OBC', 'PSEAAC', 'PSSM', 'SS', 'transformer']\n",
    "modelname = 'DNN'\n",
    "for featurename in feature_list:\n",
    "    df = pd.read_csv(f'./transfer/models/%s/%s/%s_y_label&score.csv' % (modelname, featurename, featurename))\n",
    "    label_array = df['label']\n",
    "    score_array = df['score']\n",
    "    auc_score_array = roc_auc_score(list(label_array), list(score_array))\n",
    "    #precision, recall, _ = precision_recall_curve(label_array, score_array)\n",
    "    #auc_score_array = auc(recall, precision)\n",
    "    df_scores.append(auc_score_array)\n",
    "    print(f'%s特征的%s模型的rocauc分数为：%s' % (featurename, modelname, str(auc_score_array)))\n",
    "df_scores.append(roc_auc_score(list(label), list(score)))\n",
    "pd.DataFrame(df_scores).to_csv('./transfer/models/scores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
